{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "baby_df = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "baby_df['review_clean'] = baby_df['review'].fillna(\"\").apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2\n",
    "def convert_rating(rate):\n",
    "    if rate == 3:\n",
    "        return 0\n",
    "    return -1 if rate < 3 else 1 \n",
    "\n",
    "baby_df['sentiment'] = baby_df['rating'].apply(convert_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    baby_df['review_clean'], baby_df['sentiment'], test_size=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7636)\t1\n",
      "  (0, 16657)\t1\n",
      "  (0, 18851)\t1\n",
      "  (0, 18460)\t1\n",
      "  (0, 57297)\t1\n",
      "  (0, 54469)\t1\n",
      "  (0, 58771)\t1\n",
      "  (0, 37629)\t1\n",
      "  (0, 25672)\t1\n",
      "  (0, 3405)\t2\n",
      "  (0, 38244)\t1\n",
      "  (0, 4229)\t1\n",
      "  (0, 7830)\t1\n",
      "  (0, 55192)\t1\n",
      "  (0, 51448)\t1\n",
      "  (0, 2691)\t1\n",
      "  (0, 29404)\t1\n",
      "  (0, 24315)\t1\n",
      "  (0, 37030)\t1\n",
      "  (0, 14739)\t1\n",
      "  (0, 28347)\t1\n",
      "  (0, 5053)\t1\n",
      "  (0, 5917)\t1\n",
      "  (0, 12071)\t1\n",
      "  (0, 22084)\t1\n",
      "  :\t:\n",
      "  (45880, 47379)\t4\n",
      "  (45880, 10509)\t1\n",
      "  (45880, 61241)\t1\n",
      "  (45880, 28054)\t1\n",
      "  (45880, 6661)\t1\n",
      "  (45880, 732)\t1\n",
      "  (45880, 54469)\t9\n",
      "  (45880, 37629)\t2\n",
      "  (45880, 3405)\t1\n",
      "  (45880, 38244)\t1\n",
      "  (45880, 29404)\t1\n",
      "  (45880, 55825)\t1\n",
      "  (45880, 27699)\t1\n",
      "  (45880, 29255)\t2\n",
      "  (45880, 35735)\t1\n",
      "  (45881, 43381)\t1\n",
      "  (45881, 8204)\t1\n",
      "  (45881, 9680)\t1\n",
      "  (45881, 32520)\t1\n",
      "  (45881, 33258)\t1\n",
      "  (45881, 29710)\t1\n",
      "  (45881, 38000)\t1\n",
      "  (45881, 55013)\t1\n",
      "  (45881, 54469)\t3\n",
      "  (45881, 27699)\t2\n",
      "  (0, 3405)\t1\n",
      "  (0, 3475)\t1\n",
      "  (0, 4880)\t1\n",
      "  (0, 5391)\t1\n",
      "  (0, 7830)\t1\n",
      "  (0, 9680)\t1\n",
      "  (0, 10902)\t1\n",
      "  (0, 13727)\t1\n",
      "  (0, 14838)\t1\n",
      "  (0, 17022)\t3\n",
      "  (0, 18019)\t2\n",
      "  (0, 25900)\t1\n",
      "  (0, 26984)\t1\n",
      "  (0, 27699)\t1\n",
      "  (0, 29291)\t1\n",
      "  (0, 29404)\t3\n",
      "  (0, 30242)\t1\n",
      "  (0, 33600)\t1\n",
      "  (0, 35735)\t1\n",
      "  (0, 35821)\t1\n",
      "  (0, 36702)\t1\n",
      "  (0, 55054)\t1\n",
      "  (0, 55061)\t1\n",
      "  (0, 55825)\t1\n",
      "  (0, 57559)\t1\n",
      "  :\t:\n",
      "  (137648, 50295)\t1\n",
      "  (137648, 51659)\t2\n",
      "  (137648, 51990)\t1\n",
      "  (137648, 54160)\t1\n",
      "  (137648, 54380)\t1\n",
      "  (137648, 54433)\t1\n",
      "  (137648, 54469)\t7\n",
      "  (137648, 54530)\t3\n",
      "  (137648, 54717)\t1\n",
      "  (137648, 55061)\t2\n",
      "  (137648, 55284)\t4\n",
      "  (137648, 55551)\t1\n",
      "  (137648, 55650)\t1\n",
      "  (137648, 55825)\t3\n",
      "  (137648, 56138)\t1\n",
      "  (137648, 57469)\t1\n",
      "  (137648, 58344)\t2\n",
      "  (137648, 59232)\t1\n",
      "  (137648, 60207)\t4\n",
      "  (137648, 60752)\t1\n",
      "  (137648, 60778)\t3\n",
      "  (137648, 61241)\t3\n",
      "  (137648, 61963)\t1\n",
      "  (137648, 62109)\t1\n",
      "  (137648, 62147)\t1\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern = r'\\b\\w+\\b')\n",
    "#Use thise token pattern to keep single-letter words\n",
    "#First learn vocabulary from the training data and assign columns to words\n",
    "#Then convert the training data into sparce_matrix\n",
    "train_matrix = vectorizer.fit_transform(X_train)\n",
    "words = vectorizer.get_feature_names()\n",
    "#Then convert the test data into sparce matrix, using the ane word-column mapping\n",
    "test_matrix = vectorizer.transform(X_val)\n",
    "print (train_matrix)\n",
    "print (test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janusz/anaconda3/envs/datascience/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/janusz/anaconda3/envs/datascience/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janusz/anaconda3/envs/datascience/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sentiment_model = LogisticRegression().fit(train_matrix, y_train)\n",
    "suma =sum(1 if x >= 0 else 0 for x in sentiment_model.coef_[0]) \n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9370522947090327\n",
      "baby\t0.03229842946302558\t1\n",
      "bright\t0.030816311651982394\t1\n",
      "colors\t0.240303587999553\t1\n",
      "different\t-0.305244520142297\t2\n",
      "directions\t0.40554347983808986\t1\n",
      "far\t0.4423910373395183\t1\n",
      "for\t-0.06674701691310103\t1\n",
      "fun\t0.5781866346858567\t1\n",
      "has\t0.16672689176280667\t1\n",
      "it\t-0.0637254991271183\t2\n",
      "like\t0.13248406512858835\t1\n",
      "my\t0.08415058159374841\t1\n",
      "nice\t0.5854762057683587\t1\n",
      "pieces\t-0.33205518902473286\t1\n",
      "seems\t0.06922048403364332\t1\n",
      "shapes\t0.12127777199568048\t1\n",
      "so\t0.15382801555964182\t1\n",
      "stack\t1.0774629983202295\t1\n",
      "to\t-0.046371955955025815\t1\n",
      "61643\n",
      "worst\n",
      "-2.339816805599839\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "import operator\n",
    "def score(X):\n",
    "    result = 0\n",
    "    for i in range(len(X.data)):\n",
    "        word_nr = X.indices[i]\n",
    "        result += sentiment_model.coef_[2][word_nr] * X.data[i]\n",
    "    return result\n",
    "def describe_score(X):\n",
    "    for i in range(len(X.data)):\n",
    "        word_nr = X.indices[i]\n",
    "#         result += sentiment_model.coef_[0][word_nr] * X.data[i]\n",
    "        print(words[word_nr] + \"\\t\" + str(sentiment_model.coef_[2][word_nr]) + \"\\t\" + str(X.data[i]))\n",
    "    \n",
    "    \n",
    "sample_test_data = test_matrix[3]\n",
    "print(score(sample_test_data))\n",
    "describe_score(sample_test_data)\n",
    "index, value = min(enumerate(sentiment_model.coef_[2]), key=operator.itemgetter(1))\n",
    "print(index)\n",
    "print(words[index])\n",
    "print(value)\n",
    "# sentiment_model.coef_[0].index(max_word)\n",
    "# print(max_word)\n",
    "# print(sentiment_model.coef_[0])\n",
    "# print(test_matrix[0])\n",
    "# # reprezentacja recenzji jako ilości słów\n",
    "# test_prediction = sentiment_model.predict( test_matrix)\n",
    "# print(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496479639181992\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "import math\n",
    "def proba(X):\n",
    "    score_ = score(X)\n",
    "    return 1/(1+math.exp(-score_))\n",
    "print(proba(sample_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#8\n",
    "test_prediction  = sentiment_model.predict( test_matrix)\n",
    "test_probability = sentiment_model.predict_proba(test_matrix)\n",
    "\n",
    "best_20_reviews = [x for _,x in sorted(zip(test_probability.T[0],X_val))][:20]\n",
    "worst_20_reviews = [x for _,x in sorted(zip(test_probability.T[2],X_val))][:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8378484405989146\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "correct_predictions = 0\n",
    "for i in range(len(y_val)):\n",
    "    if y_val._values[i] == test_prediction[i]:\n",
    "        correct_predictions += 1\n",
    "sentiment_model_accuracy = correct_predictions/len(y_val)\n",
    "print(sentiment_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9\n",
    "significant_words = ['love','great','easy','old','little','perfect','loves',\n",
    "                     'well','able','car','broke','less','even','waste',\n",
    "                     'disappointed','work','product','money','would','return']\n",
    "cv2 = CountVectorizer(vocabulary = significant_words) \n",
    "train_matrix_word_subset = cv2.fit_transform(X_train) \n",
    "test_matrix_word_subset  = cv2.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loves', 1.365462875125076]\n",
      "['perfect', 1.1584555584501801]\n",
      "['love', 1.1260035717396486]\n",
      "['easy', 0.8095617705519211]\n",
      "['great', 0.6822510374342685]\n",
      "['well', 0.35546475105117864]\n",
      "['little', 0.23236104218880138]\n",
      "['old', 0.11315304623069984]\n",
      "['able', 0.10186090300103184]\n",
      "['car', 0.06341588786711289]\n",
      "['product', -0.1901223822898131]\n",
      "['less', -0.21583975844389186]\n",
      "['would', -0.35916037511051807]\n",
      "['even', -0.37694795096363]\n",
      "['work', -0.6118413667803381]\n",
      "['money', -0.6309056241741858]\n",
      "['broke', -1.3639796891968898]\n",
      "['waste', -1.663195886347145]\n",
      "['return', -1.822274329575129]\n",
      "['disappointed', -2.0495494682292845]\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "simple_model = LogisticRegression().fit(train_matrix_word_subset, y_train)\n",
    "coefficient_table = []\n",
    "for i in range(len(significant_words)) :\n",
    "    coefficient_table.append([significant_words[i],simple_model.coef_[2][i]])\n",
    "sorted_by_second = sorted(coefficient_table, key=lambda tup: tup[1], reverse=True)\n",
    "# print(sorted_by_second)\n",
    "for row in sorted_by_second: print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9431585371169522\n",
      "0.788239396713308\n",
      "0.8378484405989146\n",
      "0.7875829101555405\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "sentiment_train_prediction  = sentiment_model.predict(train_matrix)\n",
    "simple_train_prediction     = simple_model   .predict(train_matrix_word_subset)\n",
    "correct_predictions_sentiment_train = 0\n",
    "correct_predictions_simple_train    = 0\n",
    "for i in range(len(y_train)):\n",
    "    if y_train._values[i] == sentiment_train_prediction[i]:\n",
    "        correct_predictions_sentiment_train += 1\n",
    "    if y_train._values[i] == simple_train_prediction[i]:\n",
    "        correct_predictions_simple_train += 1\n",
    "sentiment_train_model_accuracy = correct_predictions_sentiment_train/len(y_train)\n",
    "simple_train_model_accuracy    = correct_predictions_simple_train   /len(y_train)\n",
    "print(sentiment_train_model_accuracy)\n",
    "print(simple_train_model_accuracy)\n",
    "\n",
    "simple_test_prediction = simple_model.predict(test_matrix_word_subset)\n",
    "correct_predictions_simple_test = 0\n",
    "for i in range(len(y_val)):\n",
    "    if y_val._values[i] == simple_test_prediction[i]:\n",
    "        correct_predictions_simple_test += 1\n",
    "simple_test_model_accuracy = correct_predictions_simple_test/len(y_val)\n",
    "print(sentiment_model_accuracy)\n",
    "print(simple_test_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
